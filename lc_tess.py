# -*- coding: utf-8 -*-
"""LC_Tess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qPzzP2LuWwKYA3eRIVIDrV90rx8lQ_x4
"""

import os
import shutil

from google.colab import drive
drive.mount('/content/drive')

cd 'drive/MyDrive/Colab Notebooks/Exoplanet'

"""# Getting data of TESS telescope
#### *not run again for getting data*
---


"""

for i in range(1,77):
    os.system(f"mkdir {i}_LC")
    os.system(f"curl -R -O https://archive.stsci.edu/missions/tess/download_scripts/sector/tesscurl_sector_{i}_lc.sh")
    os.system(f"mv tesscurl_sector_{i}_lc.sh {i}_LC")

for j in range(1,77):
    f = open(f"{j}.sh","w")
    f.write(f"#!/bin/bash \n")
    f.write(f"readarray -t lines < tesscurl_sector_{j}_lc.sh\n")
    f.write("for ((i=1; i<=90; i++)); do\n")
    f.write("bash <<< \"${lines[$i]}\"\n")
    f.write("done\n")
    f.write("\")")
    f.close()
    shutil.move(f"{j}.sh", f"{j}_LC/{j}.sh")

for i in range(1,77):
    os.system(f"cd {i}_LC && bash {i}.sh")

for i in range(1,77):
    f = open(f"fits_{i}.sh","w")
    f.write("counter=1\n")
    f.write("for file in *.fits; do\n")
    f.write("new_filename=\"${counter}.fits\"\n")
    f.write("mv \"$file\" \"$new_filename\"\n")
    f.write("((counter++))\n")
    f.write("done")
    f.close()
    shutil.move(f"fits_{i}.sh", f"{i}_LC/fits_{i}.sh")
for j in range(1,77):
    os.system(f"cd {j}_LC && bash fits_{j}.sh")

"""# Plot the data of TESS
### this data's of bash codes counted. `[1.fits 2.fits ... 90.fits]`
"""

import tensorflow as tf
from astropy.io import fits
import matplotlib.pyplot as plt
import numpy as np

#information of Light Curve in exoplanet
fit = fits.open("1_LC/1.fits")
fit.info()
fit[1].header

fit[1].data

data_fit = fit[1].data
data2_fit = fit[2].data
fig, ax = plt.subplots(2)
ax[0].set_title(fit[1].header['OBJECT'])
ax[0].plot(data2_fit)
ax[0].set_xlim([2,7])
ax[1].plot(data_fit['TIME'], data_fit['SAP_FLUX'])
ax[1].legend([fit[1].header['DATE-OBS']])
ax[1].set_xlim([1347,1350])
plt.savefig('fit1.png')

fit2 = fits.open("1_LC/2.fits")
fit2.info()
fit2[1].header

data_fit2 = fit2[1].data
data2_fit2 = fit2[2].data

fig, ax = plt.subplots(2)
ax[0].set_title(fit2[1].header['OBJECT'])
ax[0].plot(data2_fit2)
ax[0].set_xlim([2,7])
ax[1].plot(data_fit2['TIME'], data_fit2['SAP_FLUX'])
ax[1].set_xlim([1347,1350])
ax[1].legend([fit2[1].header['DATE-OBS']])
plt.savefig('fit2.png')

### Light Curve from all data's of 1_LC folder
for i in range(1,90):
    fits_all = fits.open(f"1_LC/{i}.fits")
    print(fits_all[1].header['OBJECT'])
    data_fits_all = fits_all[1].data
    plt.xlim([1347,1349.8])
    plt.plot(data_fits_all['TIME'], data_fits_all['SAP_FLUX'])
plt.title("Light Curve")
plt.xlabel("TIME")
plt.ylabel("FLUX")
plt.savefig(f"1_LC_fits_all.png")

for i in range(1,77):
  for j in range(1,90):
    fits_all = fits.open(f"{i}_LC/{j}.fits")
  data_fits_all = fits_all[1].data
  print(fits_all[1].header['OBJECT'])
  plt.plot(data_fits_all['TIME'], data_fits_all['SAP_FLUX'])
plt.title("All Fits of exoplanet at Light Curve")
plt.xlabel("TIME")
plt.ylabel("FLUX")
plt.savefig("fits_all_stars.png")

"""# Image of data's FLUX
### This data is on the brightness and is `imshow`.
---
"""

plt.imshow(data2_fit2)

for i in range(1,77):
  for j in range(1,90):
    fits_all_LC = fits.open(f"{i}_LC/{j}.fits")
  data2 = fits_all_LC[2].data
  plt.imshow(data2)
  plt.colorbar()
  plt.show()

"""# Normalization of Light Curve

---
"""

def Normalization(data):
  min_val = min(data)
  max_val = max(data)
  return (data - min_val)/(max_val - min_val)

plt.plot(data_fit2['TIME'],Normalization(data_fit2['SAP_FLUX']))
plt.xlim([1347,1350])

for i in range(1,90):
    fits_all = fits.open(f"1_LC/{i}.fits")
    data_fits_all = fits_all[1].data
    plt.plot(Normalization(data_fits_all['TIME']), Normalization(data_fits_all['SAP_FLUX']))
plt.title("Light Curve")
plt.xlabel("TIME")
plt.ylabel("FLUX")
plt.savefig(f"1_LC_fits_all_norm.png")

for i in range(1,77):
  for j in range(1,90):
    fits_all = fits.open(f"{i}_LC/{j}.fits")
  data_fits_all = fits_all[1].data
  plt.plot(Normalization(data_fits_all['TIME']), Normalization(data_fits_all['SAP_FLUX']))
plt.title("Normalization of All Fits of the exoplanet at Light Curve")
plt.xlabel("TIME")
plt.ylabel("FLUX")
plt.savefig("fits_all_stars_norm.png")

"""# Getting and Extraction sun data to The Light Curve."""

import os

os.system("curl -R -O https://soho.nascom.nasa.gov/data/EntireMissionBundles/GOLF_26y_PM1.fits")
os.system("curl -R -O https://soho.nascom.nasa.gov/data/EntireMissionBundles/VIRGO-LOI-ALL-PIXELS-LEVEL2-19960401-20210430_V01.fits && mv VIRGO-LOI-ALL-PIXELS-LEVEL2-19960401-20210430_V01.fits SunData.fits")

import os
os.system("curl -R -O https://soho.nascom.nasa.gov/data/EntireMissionBundles/VIRGO_TSI_daily_hourly.zip")
os.system("unzip VIRGO_TSI_daily_hourly.zip")
os.remove("VIRGO_TSI_daily_hourly.zip")

ls

# https://soho.nascom.nasa.gov/data/EntireMissionBundles/

import os
import glob
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D
from scipy.interpolate import interp1d
from astropy.io import fits

"""## Reading File Sun Data"""

solar_data_time = []
solar_data_flux = []
with open("VIRGO_TSI_Daily_V8_20250330.txt", "r") as file:
    for line in file:
        line = line.strip()
        if not line or line.startswith(";"):
            continue
        parts = line.split()
        if len(parts) < 2:
            continue
        try:
            solar_data_time.append(parts[0])
            solar_data_flux.append(float(parts[1]))
        except ValueError:
            print("Error converting value to number; skipping line:", line)

solar_data_flux = np.array(solar_data_flux)
solar_times_numeric = np.arange(len(solar_data_flux))

"""## Reading ExoPlanet Data of (TESS) .fits
#### All Data of Exoplanet processing
``` This takes times ```
"""

exoplanet_times = []
exoplanet_fluxes = []

for i in range(1, 77):
    folder = f"{i}_LC"
    files = glob.glob(os.path.join(folder, "*.fits"))
    for fname in files:
        try:
            with fits.open(fname) as hdul:
                data = hdul[1].data
                if 'TIME' in data.names and 'PDCSAP_FLUX' in data.names:
                    times = data['TIME']
                    fluxes = data['PDCSAP_FLUX']
                elif 'TIME' in data.names and 'SAP_FLUX' in data.names:
                    times = data['TIME']
                    fluxes = data['SAP_FLUX']
                else:
                    continue
                for t, f_val in zip(times, fluxes):
                    if np.isfinite(t) and np.isfinite(f_val):
                        exoplanet_times.append(t)
                        exoplanet_fluxes.append(f_val)
        except Exception as e:
            print(f"Error File Reading: {fname}: {e}")

exoplanet_times = np.array(exoplanet_times)
exoplanet_fluxes = np.array(exoplanet_fluxes)

if exoplanet_times.size == 0:
    raise RuntimeError("No real Exoplanet data found! Please check the data files.")

sort_idx = np.argsort(exoplanet_times)
exoplanet_times = exoplanet_times[sort_idx]
exoplanet_fluxes = exoplanet_fluxes[sort_idx]

"""## Time matching of extrasolar data with solar data"""

interp_func = interp1d(exoplanet_times, exoplanet_fluxes, kind='linear', fill_value="extrapolate")
matched_exoplanet_flux = interp_func(solar_times_numeric)

print("Number of solar data:", len(solar_data_flux))
print("Number of extrasolar data after matching:", len(matched_exoplanet_flux))

solar_array = solar_data_flux.reshape(-1, 1)
matched_exoplanet_array = matched_exoplanet_flux.reshape(-1, 1)

"""## Computing the closest extrasolar data to the Sun and storing more information"""

threshold = 0.5

flux_difference = np.abs(solar_data_flux - matched_exoplanet_flux)
sorted_indices = np.argsort(flux_difference)
top_n_matches = 100
closest_indices = sorted_indices[:top_n_matches]

closest_solar_flux = solar_data_flux[closest_indices]
closest_exoplanet_flux = matched_exoplanet_flux[closest_indices]
closest_time = solar_times_numeric[closest_indices]
closest_diff = flux_difference[closest_indices]

matched_data = np.column_stack((closest_indices, closest_time, closest_solar_flux, closest_exoplanet_flux, closest_diff))
header = "Index, Time, Solar Flux, Exoplanet Flux, Abs Difference"
np.savetxt("approximate_closest_matches.txt", matched_data, header=header, comments="", fmt=["%d", "%.2f", "%.6f", "%.6f", "%.6f"])

print(f"Number of close data (with threshold {threshold}): {len(closest_indices)}")

"""## Building and training a CNN model for data analysis"""

solar_data_cnn = solar_data_flux.reshape(1, len(solar_data_flux), 1)
matched_exoplanet_data_cnn = matched_exoplanet_flux.reshape(1, len(matched_exoplanet_flux), 1)

def create_cnn_model(input_shape):
    model = Sequential()
    model.add(Conv1D(32, kernel_size=1, activation='relu', input_shape=input_shape))
    model.add(MaxPooling1D(pool_size=1))
    model.add(Flatten())
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

cnn_model = create_cnn_model((len(solar_data_flux), 1))
cnn_labels = np.array([0, 1])
cnn_data = np.concatenate((solar_data_cnn, matched_exoplanet_data_cnn), axis=0)

cnn_model.fit(cnn_data, cnn_labels, epochs=5, verbose=1)
predicted_cnn = cnn_model.predict(solar_data_cnn)
print("CNN Predictions:", predicted_cnn)

"""## Drawing a diagram comparing solar and extrasolar light curves"""

plt.figure(figsize=(10, 6))
plt.plot(solar_times_numeric, solar_data_flux, label="Solar Data", marker='o')
plt.plot(solar_times_numeric, matched_exoplanet_flux, label="Matched Exoplanet Data", marker='x')
plt.xlabel("Time")
plt.ylabel("Flux")
plt.title("Comparison of Solar and Exoplanet Light Curves")
plt.savefig("Solar_Exoplanet.png")
plt.legend()
plt.grid(True)
plt.show()

import os
import glob
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
from astropy.io import fits
import random

# 1. خواندن داده‌های خورشید
solar_data_time = []
solar_data_flux = []
with open("VIRGO_TSI_Daily_V8_20250330.txt", "r") as file:
    for line in file:
        line = line.strip()
        if not line or line.startswith(";"):
            continue
        parts = line.split()
        if len(parts) < 2:
            continue
        try:
            solar_data_time.append(parts[0])
            solar_data_flux.append(float(parts[1]))
        except ValueError:
            print("خطا در تبدیل مقدار به عدد؛ رد کردن خط:", line)

solar_data_flux = np.array(solar_data_flux)
solar_times_numeric = np.arange(len(solar_data_flux))

# تابع درون‌یاب برای شار خورشید
solar_interp = interp1d(solar_times_numeric, solar_data_flux, kind='linear', fill_value="extrapolate")

# 2. جمع‌آوری داده‌ها و محاسبه ضریب همبستگی
correlations = []
data_for_plot = []
for i in range(1, 77):  # فرضاً پوشه‌ها از 1_LC تا 76_LC
    folder = f"{i}_LC"
    files = glob.glob(os.path.join(folder, "*.fits"))
    for fname in files:
        try:
            with fits.open(fname) as hdul:
                data = hdul[1].data
                if 'TIME' in data.names and 'PDCSAP_FLUX' in data.names:
                    times = data['TIME']
                    fluxes = data['PDCSAP_FLUX']
                elif 'TIME' in data.names and 'SAP_FLUX' in data.names:
                    times = data['TIME']
                    fluxes = data['SAP_FLUX']
                else:
                    continue
                mask = np.isfinite(times) & np.isfinite(fluxes)
                times = times[mask]
                fluxes = fluxes[mask]
                if len(times) < 2:
                    continue
                solar_flux_at_exo_times = solar_interp(times)
                corr = np.corrcoef(solar_flux_at_exo_times, fluxes)[0, 1]
                correlations.append((fname, corr))
                data_for_plot.append((fname, solar_flux_at_exo_times, fluxes))
        except Exception as e:
            print(f"خطا در پردازش فایل {fname}: {e}")

# 3. انتخاب 10 سیاره با بالاترین ضریب همبستگی
sorted_correlations = sorted(correlations, key=lambda x: abs(x[1]), reverse=True)
selected_planets = sorted_correlations[:10]  # فقط 10 سیاره برتر

# 4. رسم نمودار پراکندگی
plt.figure(figsize=(10, 8))
colors = plt.cm.tab10(np.linspace(0, 1, len(selected_planets)))  # رنگ‌های مختلف
for idx, (fname, corr) in enumerate(selected_planets):
    # پیدا کردن داده‌های سیاره
    for name, solar_flux, exo_flux in data_for_plot:
        if name == fname:
            plt.scatter(solar_flux, exo_flux, label=f"{os.path.basename(fname)} (Corr: {corr:.2f})",
                        color=colors[idx], alpha=0.6, s=50)
            break

plt.xlabel("Sun Flux")
plt.ylabel("Exoplanet Flux")
plt.title("Correlation of Sun and Exoplanet flux")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("scatter_correlation.png")
plt.show()

import os
import glob
import numpy as np
from scipy.interpolate import interp1d
from astropy.io import fits

# 1. خواندن داده‌های خورشید
solar_data_time = []
solar_data_flux = []
with open("VIRGO_TSI_Daily_V8_20250330.txt", "r") as file:
    for line in file:
        line = line.strip()
        if not line or line.startswith(";"):
            continue
        parts = line.split()
        if len(parts) < 2:
            continue
        try:
            solar_data_time.append(parts[0])
            solar_data_flux.append(float(parts[1]))
        except ValueError:
            print("خطا در تبدیل مقدار به عدد؛ رد کردن خط:", line)

solar_data_flux = np.array(solar_data_flux)
solar_times_numeric = np.arange(len(solar_data_flux))

# تابع درون‌یاب برای شار خورشید
solar_interp = interp1d(solar_times_numeric, solar_data_flux, kind='linear', fill_value="extrapolate")

# 2. جستجو برای پیدا کردن 83.fits
for i in range(1, 77):  # فرضاً پوشه‌ها از 1_LC تا 76_LC
    folder = f"{i}_LC"
    files = glob.glob(os.path.join(folder, "*.fits"))
    for fname in files:
        if os.path.basename(fname) == "58.fits":  # چک کردن نام فایل
            print(f"founded for {folder}")
            # محاسبه ضریب همبستگی برای تأیید
            try:
                with fits.open(fname) as hdul:
                    data = hdul[1].data
                    if 'TIME' in data.names and 'PDCSAP_FLUX' in data.names:
                        times = data['TIME']
                        fluxes = data['PDCSAP_FLUX']
                    elif 'TIME' in data.names and 'SAP_FLUX' in data.names:
                        times = data['TIME']
                        fluxes = data['SAP_FLUX']
                    else:
                        continue
                    mask = np.isfinite(times) & np.isfinite(fluxes)
                    times = times[mask]
                    fluxes = fluxes[mask]
                    if len(times) < 2:
                        continue
                    solar_flux_at_exo_times = solar_interp(times)
                    corr = np.corrcoef(solar_flux_at_exo_times, fluxes)[0, 1]
                    print(f"correlaction for  {fname}: {corr:.2f}")
            except Exception as e:
                print(f"خطا در پردازش فایل {fname}: {e}")

from astropy.io import fits
import matplotlib.pyplot as plt
fit = fits.open('21_LC/83.fits')
fit2 = fits.open("45_LC/58.fits")
fit.info()
fit2.info()
plt.imshow(fit[2].data)
plt.show()
plt.imshow(fit2[2].data)
plt.show()

